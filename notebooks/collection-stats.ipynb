{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import geopandas\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = '/g/data/v10/projects/gaip-scripts/harvest-collection/collection-completeness.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the file see what datasets have been recored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/oth_and_children_products', '/sys_products']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store = pandas.HDFStore(fname, 'r')\n",
    "store.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the ORTHO and SYS records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oth_df = store['/oth_and_children_products']\n",
    "sys_df = store['/sys_products']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the two tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pandas.concat([oth_df, sys_df], keys=['oth', 'sys'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The counts recorded for L1_L1T, L1_L1Gt, L0_success are recorded as a pass level. So the values will actually\n",
    "be duplicated where records/scenes have come from the same pass.\n",
    "\n",
    "So what we need to do is find the children products, and calculate a sum. Then remove any records with a \n",
    "duplicate `pass_name`. This should yield a count of products, including any children products, for a given pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_children(dataframe):\n",
    "    cols = ['pass_name', 'nbar_exists', 'nbart_exists', 'pq_exists']\n",
    "    children = pandas.DataFrame(columns=cols)\n",
    "    cols.remove('pass_name')\n",
    "    \n",
    "    # for each scene with the same pass name, group and sum the records\n",
    "    groups = dataframe.groupby('pass_name')\n",
    "    for name, group in groups:\n",
    "        res = group[cols].sum()\n",
    "        res['pass_name'] = name\n",
    "        children = children.append(res, ignore_index=True)\n",
    "        \n",
    "    children.rename(columns={'nbar_exists': 'nbar',\n",
    "                             'nbart_exists': 'nbart',\n",
    "                             'pq_exists': 'pq'}, inplace=True)\n",
    "    \n",
    "    # merge the input dataframe and the summed child products, and drop any duplicate passes\n",
    "    merged = pandas.merge(dataframe, children, on=['pass_name'])\n",
    "    result = merged.drop_duplicates('pass_name')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = merge_children(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the columns that'll be used for reporting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['sensor',\n",
    "        'date',\n",
    "        'L0_fail',\n",
    "        'L0_success',\n",
    "        'L1_fail',\n",
    "        'L1_success',\n",
    "        'L1_L1G',\n",
    "        'L1_L1Gt',\n",
    "        'L1_L1T',\n",
    "        'nbar',\n",
    "        'nbart',\n",
    "        'pq']\n",
    "result = merged[cols]\n",
    "result.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor</th>\n",
       "      <th>L0_fail</th>\n",
       "      <th>L0_success</th>\n",
       "      <th>L1_fail</th>\n",
       "      <th>L1_success</th>\n",
       "      <th>L1_L1G</th>\n",
       "      <th>L1_L1Gt</th>\n",
       "      <th>L1_L1T</th>\n",
       "      <th>nbar</th>\n",
       "      <th>nbart</th>\n",
       "      <th>pq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1991-05-21</th>\n",
       "      <td>LS5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-05-31</th>\n",
       "      <td>LS5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-05-02</th>\n",
       "      <td>LS5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-05-05</th>\n",
       "      <td>LS5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991-05-08</th>\n",
       "      <td>LS5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           sensor  L0_fail  L0_success  L1_fail  L1_success  L1_L1G  L1_L1Gt  \\\n",
       "date                                                                           \n",
       "1991-05-21    LS5      0.0        25.0      1.0        23.0     8.0      0.0   \n",
       "1991-05-31    LS5      0.0        25.0      1.0        23.0    10.0      0.0   \n",
       "1991-05-02    LS5      0.0        24.0      1.0        23.0     8.0      0.0   \n",
       "1991-05-05    LS5      0.0        26.0      1.0        24.0     6.0      0.0   \n",
       "1991-05-08    LS5      0.0        24.0      1.0        22.0     4.0      0.0   \n",
       "\n",
       "            L1_L1T  nbar  nbart    pq  \n",
       "date                                   \n",
       "1991-05-21    15.0  12.0   12.0  12.0  \n",
       "1991-05-31    13.0  13.0   13.0  13.0  \n",
       "1991-05-02    15.0  15.0   15.0  15.0  \n",
       "1991-05-05    18.0  15.0   15.0  15.0  \n",
       "1991-05-08    18.0  18.0   18.0  18.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the results on a per-sensor basis, with aggregate summation based on the Month, to the Excel file format.\n",
    "\n",
    "Excel format requires xlwt which is currently not available within the `agdc-py2-prod` module.\n",
    "\n",
    "So we'll output to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collection_stats(dataframe, out_fname_fmt):\n",
    "    groups = dataframe.groupby('sensor')\n",
    "    for sensor, group in groups:\n",
    "        outdf = group.resample('M').apply(sum)\n",
    "\n",
    "        exp = \"L0_completeness = L0_success / (L0_success + L0_fail) * 100\"\n",
    "        outdf.eval(exp, inplace=True)\n",
    "        exp = \"L1_completeness = L1_success / (L1_success + L1_fail) * 100\"\n",
    "        outdf.eval(exp, inplace=True)\n",
    "        exp = \"nbar_completeness = nbar / (L1_L1T + L1_L1Gt) * 100\"\n",
    "        outdf.eval(exp, inplace=True)\n",
    "        exp = \"nbart_completeness = nbart / (L1_L1T + L1_L1Gt) * 100\"\n",
    "        outdf.eval(exp, inplace=True)\n",
    "        exp = \"pq_completeness = pq / (L1_L1T + L1_L1Gt) * 100\"\n",
    "        outdf.eval(exp, inplace=True)\n",
    "        exp = \"pq_completeness_relative = pq / nbar * 100\"\n",
    "        outdf.eval(exp, inplace=True)\n",
    "\n",
    "        out_fname = out_fname_fmt.format(sensor)\n",
    "        outdf.to_csv(out_fname)\n",
    "        # outdf.to_excel(out_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# out_fname_fmt = '/g/data/v10/projects/gaip-scripts/harvest-collection/{}.xls'\n",
    "out_fname_fmt = '/g/data/v10/projects/gaip-scripts/harvest-collection/{}.csv'\n",
    "collection_stats(result, out_fname_fmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also filter the scenes to report only on those that are within GA's nominal path/row schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subset_to_nominal_path_row(dataframe):\n",
    "    \"\"\"\n",
    "    Given a `pandas.DataFrame` created from a trawling of lpgs_out.xml files,\n",
    "    subset the list of scenes to GA's nominal path/row processing selection.\n",
    "    \n",
    "    :param dataframe:\n",
    "        A `pandas.DataFrame`.\n",
    "        \n",
    "    :return:\n",
    "        A `geopandas.GeoDataFrame`.\n",
    "    \"\"\"\n",
    "    nominal_fname = '/g/data/v10/eoancillarydata/ga-nominal-scenes/ADGC_v2_Area_of_Interest.shp'\n",
    "    gdf = geopandas.read_file(nominal_fname)\n",
    "    gdf.rename(columns={'PATH': 'path', 'ROW': 'row'}, inplace=True)\n",
    "    \n",
    "    df = pandas.merge(dataframe, gdf, on=['path', 'row'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oth_df = store['/oth_and_children_products']\n",
    "sys_df = store['/sys_products']\n",
    "df = pandas.concat([oth_df, sys_df], keys=['oth', 'sys'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nominal = subset_to_nominal_path_row(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. scenes in whole collection: 456007\n",
      "No. of scenes within Nominal processing: 366288\n"
     ]
    }
   ],
   "source": [
    "print \"No. scenes in whole collection: {}\".format(df.shape[0])\n",
    "print \"No. of scenes within Nominal processing: {}\".format(nominal.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged = merge_children(nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['sensor',\n",
    "        'date',\n",
    "        'L0_fail',\n",
    "        'L0_success',\n",
    "        'L1_fail',\n",
    "        'L1_success',\n",
    "        'L1_L1G',\n",
    "        'L1_L1Gt',\n",
    "        'L1_L1T',\n",
    "        'nbar',\n",
    "        'nbart',\n",
    "        'pq']\n",
    "result = merged[cols]\n",
    "result.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# out_fname_fmt = '/g/data/v10/projects/gaip-scripts/harvest-collection/{}-roi.xls'\n",
    "out_fname_fmt = '/g/data/v10/projects/gaip-scripts/harvest-collection/{}-roi.csv'\n",
    "collection_stats(result, out_fname_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
